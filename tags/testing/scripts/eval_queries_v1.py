from __future__ import annotations

import csv
import os
import random
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
from sentence_transformers import SentenceTransformer

ROOT = Path(__file__).resolve().parents[2]
DATA_DIR = ROOT / "testing" / "data"
LOG_DIR = ROOT / "testing" / "logs"

TAGS_PATH = DATA_DIR / "t_tag_PLANNING.txt"
TOPICS_PATH = DATA_DIR / "t_topic_PLANNING.csv"
ASSIGN_PATH = DATA_DIR / "ct_topic_tags_PLANNING.csv.txt"
LOG_PATH = LOG_DIR / "tag_eval_v1.txt"

MODEL_NAME = os.getenv(
    "TAG_MODEL_NAME", "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
)
QUERY_TOP_K = int(os.getenv("QUERY_TOP_K", "7"))
QUERY_SAMPLE_SIZE = int(os.getenv("QUERY_SAMPLE_SIZE", "8"))
QUERY_SAMPLE_SEED = os.getenv("QUERY_SAMPLE_SEED")
QUERY_MIN_SIM = float(os.getenv("QUERY_MIN_SIM", "0.2"))
QUERY_TEMP = float(os.getenv("QUERY_WEIGHT_TEMP", "0.08"))
TOP_N_CANDIDATES = int(os.getenv("TOP_N_CANDIDATES", "250"))
RELATIVE_MIN_FACTOR = float(os.getenv("RELATIVE_MIN_FACTOR", "0.333333"))
ABS_MIN_PREFILTER = float(os.getenv("ABS_MIN_PREFILTER", "0.02"))
TOP_FINAL = int(os.getenv("TOP_FINAL", "20"))


@dataclass(frozen=True)
class Tag:
    tag_id: int
    name: str
    synonyms: List[str]


@dataclass(frozen=True)
class Topic:
    topic_id: str
    name: str
    description: str


def load_tags(path: Path) -> List[Tag]:
    tags: List[Tag] = []
    with path.open("r", encoding="utf-8", newline="") as handle:
        reader = csv.DictReader(handle)
        for row in reader:
            tag_id_raw = (row.get("tagID") or "").strip()
            name = (row.get("name") or "").strip()
            synonyms_raw = (row.get("synonyms") or "").strip()
            if not tag_id_raw or not name:
                continue
            try:
                tag_id = int(tag_id_raw)
            except ValueError:
                continue
            synonyms = [part.strip() for part in synonyms_raw.split(",") if part.strip()]
            tags.append(Tag(tag_id=tag_id, name=name, synonyms=synonyms))
    return tags


def load_topics(path: Path) -> List[Topic]:
    topics: List[Topic] = []
    with path.open("r", encoding="utf-8", newline="") as handle:
        reader = csv.DictReader(handle)
        for row in reader:
            topic_id = (row.get("topicID") or "").strip()
            name = (row.get("name") or "").strip()
            description = (row.get("description") or "").strip()
            if not topic_id or not name:
                continue
            topics.append(Topic(topic_id=topic_id, name=name, description=description))
    return topics


def load_assignments(path: Path) -> Dict[str, Dict[int, float]]:
    mapping: Dict[str, Dict[int, float]] = {}
    with path.open("r", encoding="utf-8", newline="") as handle:
        reader = csv.DictReader(handle)
        for row in reader:
            topic_id = (row.get("topicID") or "").strip()
            tag_id_raw = (row.get("tagID") or "").strip()
            weight_raw = (row.get("weight") or "").strip()
            if not topic_id or not tag_id_raw or not weight_raw:
                continue
            try:
                tag_id = int(tag_id_raw)
            except ValueError:
                continue
            mapping.setdefault(topic_id, {})[tag_id] = float(weight_raw)
    return mapping


def build_tag_variants(tags: List[Tag]) -> Tuple[List[str], List[List[int]]]:
    variant_texts: List[str] = []
    tag_variant_indices: List[List[int]] = []
    for tag in tags:
        variants = [tag.name] + tag.synonyms
        indices: List[int] = []
        for variant in variants:
            variant_texts.append(f"Tag: {variant}.")
            indices.append(len(variant_texts) - 1)
        tag_variant_indices.append(indices)
    return variant_texts, tag_variant_indices


def topic_text(topic: Topic) -> str:
    if topic.description:
        return f"{topic.name}. {topic.description}"
    return topic.name


def softmax(scores: np.ndarray, temperature: float) -> np.ndarray:
    if scores.size == 0:
        return scores
    scaled = scores / max(temperature, 1e-6)
    scaled = scaled - np.max(scaled)
    exp_scores = np.exp(scaled)
    return exp_scores / np.sum(exp_scores)


def query_tag_weights(
    tag_scores: np.ndarray, tags: List[Tag]
) -> Dict[int, Tuple[str, float, float]]:
    order = np.argsort(tag_scores)[::-1]
    top_indices = order[: max(QUERY_TOP_K, 1)].tolist()
    filtered = [i for i in top_indices if float(tag_scores[i]) >= QUERY_MIN_SIM]
    if not filtered:
        filtered = [top_indices[0]]
    kept_scores = np.array([float(tag_scores[i]) for i in filtered], dtype=float)
    weights = softmax(kept_scores, QUERY_TEMP)
    output: Dict[int, Tuple[str, float, float]] = {}
    for local_idx, (idx, weight) in enumerate(zip(filtered, weights)):
        output[tags[idx].tag_id] = (
            tags[idx].name,
            float(kept_scores[local_idx]),
            float(weight),
        )
    return output


def main() -> None:
    tags = load_tags(TAGS_PATH)
    topics = load_topics(TOPICS_PATH)
    assignments = load_assignments(ASSIGN_PATH)
    if not tags or not topics or not assignments:
        raise SystemExit("Missing tags, topics, or assignments.")

    model = SentenceTransformer(MODEL_NAME)
    tag_inputs, tag_variant_indices = build_tag_variants(tags)
    topic_inputs = [topic_text(topic) for topic in topics]

    tag_variant_emb = model.encode(
        tag_inputs, normalize_embeddings=True, show_progress_bar=True
    )
    topic_emb = model.encode(
        topic_inputs, normalize_embeddings=True, show_progress_bar=True
    )

    topic_by_id = {topic.topic_id: topic for topic in topics}
    topic_index = {topic.topic_id: idx for idx, topic in enumerate(topics)}

    queries = [
        "Me gustan los dinos y los volcanes. y tambiÃ©n el espacio!! ðŸš€ðŸ¦•",
        "Why is the sky blue and how does an airplane fly?",
        "Aku pengin tahu gimana cara bikin game di komputer dan gimana robot bekerja.",
        "Je mâ€™intÃ©resse aux animaux, mais pas seulement aux animaux mignons, aussi les requins, les araignÃ©es et tout Ã§a. Et comment ils vivent en vrai.",
        "I want to be a police officer or a firefighter later (or a vet). I also like cars and how engines work.",
        "æˆ‘è¶…çˆ±åŽ†å²ï¼Œå°¤å…¶æ˜¯ç½—é©¬å’ŒåŸƒåŠï¼Œä½†æˆ‘ä¸æ‡‚æ€Žä¹ˆæŠŠè¿™äº›éƒ½è®°ä½ ðŸ˜­",
        "à¦†à¦®à¦¿ à¦–à§à¦¬ à¦†à¦—à§à¦°à¦¹à§€: à¦®à¦¹à¦¾à¦•à¦¾à¦¶, à¦¬à§à¦²à§à¦¯à¦¾à¦• à¦¹à§‹à¦², à¦à¦²à¦¿à¦¯à¦¼à§‡à¦¨ (à¦¯à¦¦à¦¿à¦“ à¦¸à¦®à§à¦­à¦¬à¦¤ à¦¸à§‡à¦Ÿà¦¾ à¦«à§‡à¦•), à¦†à¦° à¦ªà¦¦à¦¾à¦°à§à¦¥à¦¬à¦¿à¦œà§à¦žà¦¾à¦¨â€”à¦†à¦²à§‹ à¦†à¦° à¦¸à¦®à¦¯à¦¼ à¦Ÿà¦¾à¦‡à¦ªà§‡à¦° à¦œà¦¿à¦¨à¦¿à¦¸à¥¤",
        "Mujhe bohot interest hai ke paisa kaise banate hain lol. Like economy, stocks, startup aur aisi cheezen. Aur psychology bhi ke log kyun kharidte hain.",
        "Eu me interesso por medicina. Como os Ã³rgÃ£os funcionam? Por que a gente fica doente? E o que acontece numa cirurgia?",
        "Iâ€™m into politics and debates and how laws are made. Also human rights, democracy, the EU and stuff. And how to convince people.",
        "æ—¥æœ¬èªžã§æ›¸ãã‘ã©ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ï¼ˆPython/Javaã¡ã‚‡ã£ã¨ï¼‰ã¨æ•°å­¦ã¨è«–ç†ãŒå¥½ãã€‚ã‚ã¨AIãŒã©ã†å‹•ãã®ã‹ã€ä½¿ã†ã ã‘ã˜ã‚ƒãªãã¦ç†è§£ã—ãŸã„ã€‚",
        "Ð¯ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑƒÑŽÑÑŒ Ð¸ÑÐºÑƒÑÑÑ‚Ð²Ð¾Ð²ÐµÐ´ÐµÐ½Ð¸ÐµÐ¼, Ñ„Ð¸Ð»Ð¾ÑÐ¾Ñ„Ð¸ÐµÐ¹ Ð¸ Ð»Ð¸Ñ‚ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð¾Ð¹. ÐžÑÐ¾Ð±ÐµÐ½Ð½Ð¾ ÑÐºÐ·Ð¸ÑÑ‚ÐµÐ½Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¼Ð¾Ð¼, ÑÐ¼Ñ‹ÑÐ»Ð¾Ð¼ Ð¶Ð¸Ð·Ð½Ð¸, Ð¼Ð¾Ñ€Ð°Ð»ÑŒÑŽ Ð¸ Ñ‚.Ð´.",
        "I might want to become an engineer (aerospace or mechanical). Iâ€™m especially into technical systems: turbines, aerodynamics, spaceflight.",
        "Me gusta todo lo de Minecraft y construir, pero quiero saber cÃ³mo se hace en la vida real: casas, puentes y esas cosas.",
        "MÉ™n elektrik nÉ™dir baÅŸa dÃ¼ÅŸmÉ™k istÉ™yirÉ™m?? YÉ™ni niyÉ™ dÃ¼ymÉ™ni basanda iÅŸÄ±q yanÄ±r?",
        "I love EVERYTHING about dinosaurs, seriously everything. What species existed? Why did they go extinct? Could they still exist today?",
        "Saya tertarik sama masak dan makanan, dan juga kenapa makanan itu sehat atau tidak. Sama olahraga dikit.",
        "Vorrei fare la designer o qualcosa con la moda, ma anche fotografia e montaggio video.",
        "Iâ€™m into true crime (sorry) and I want to know how forensics works. Fingerprints, DNA, crime scenes, forensic medicine.",
        "æˆ‘è§‰å¾—è¯­è¨€å¾ˆæœ‰æ„æ€ï¼Œå°¤å…¶æ˜¯è‹±è¯­ã€æ—¥è¯­ï¼Œè¿˜æœ‰è¯­æ³•æ€Žä¹ˆè¿ä½œã€‚ä¹Ÿæƒ³çŸ¥é“è¯è¯­çš„æ¥æºã€‚",
        "ÐœÐ½Ðµ Ð¾Ñ‡ÐµÐ½ÑŒ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾ Ð¿Ñ€Ð¾ Ð¾ÐºÑ€ÑƒÐ¶Ð°ÑŽÑ‰ÑƒÑŽ ÑÑ€ÐµÐ´Ñƒ Ð¸ ÐºÐ»Ð¸Ð¼Ð°Ñ‚. ÐÐ°ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ Ð²ÑÑ‘ Ð¿Ð»Ð¾Ñ…Ð¾? Ð§Ñ‚Ð¾ Ð¼Ð¾Ð¶Ð½Ð¾ ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ? Ð˜ Ñ‡Ñ‚Ð¾ Ñ‚Ð°ÐºÐ¾Ðµ Ñ„ÐµÐ¹Ðº-Ð½ÑŒÑŽÑ?",
        "Ich interessiere mich fÃ¼r Geschichte, aber eher ab 1900 (1. & 2. Weltkrieg, Kalter Krieg, Propaganda). Und politische Ideologien.",
        "Iâ€™m into music production: beats, mixing, sound design, but also the physics of sound and how speakers work.",
        "Je mâ€™intÃ©resse beaucoup au droit : droit pÃ©nal, droit constitutionnel, tribunaux internationaux. Et aussi lâ€™Ã©thique derriÃ¨re tout Ã§a.",
        "Quiero saber cÃ³mo dibujar un caballo y cÃ³mo se hace un arcoÃ­ris ðŸŒˆ",
        "I want to learn about stars and why they twinkle. And about planets.",
        "à¤®à¥ˆà¤‚ à¤œà¤¾à¤¨à¤¨à¤¾ à¤šà¤¾à¤¹à¤¤à¤¾ à¤¯à¤¾ à¤šà¤¾à¤¹à¤¤à¥€ à¤¹à¥‚à¤ à¤•à¤¿ à¤¯à¥‚à¤Ÿà¥à¤¯à¥‚à¤¬ à¤•à¥ˆà¤¸à¥‡ à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¤”à¤° à¤µà¥€à¤¡à¤¿à¤¯à¥‹ à¤µà¤¾à¤¯à¤°à¤² à¤•à¥à¤¯à¥‹à¤‚ à¤¹à¥‹ à¤œà¤¾à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤",
        "ÐœÐµÐ½Ñ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑƒÐµÑ‚ Ñ…Ð¸Ð¼Ð¸Ñ, Ð½Ð¾ Ñ Ð½Ðµ Ð¾Ñ‡ÐµÐ½ÑŒ Ñ€Ð°Ð·Ð±Ð¸Ñ€Ð°ÑŽÑÑŒ. Ð§Ñ‚Ð¾ Ð²Ð¾Ð¾Ð±Ñ‰Ðµ Ñ‚Ð°ÐºÐ¾Ðµ Ð°Ñ‚Ð¾Ð¼?",
        "Por que as pessoas brigam tanto? Como dÃ¡ pra resolver isso? Acho que quero ser psicÃ³logo/psicÃ³loga.",
        "ì €ëŠ” ìˆ˜í•™ì„ ì¢‹ì•„í•´ìš” (ì§„ì§œë¡œ) ê·¸ë¦¬ê³  í¼ì¦ ê°™ì€ ê±°ìš”. ê·¸ë¦¬ê³  ì´ê±¸ ë‚˜ì¤‘ì— ì–´ë””ì— ì“°ëŠ”ì§€ë„ ì•Œê³  ì‹¶ì–´ìš”.",
        "Iâ€™m interested in animals and nature, but also plants. Which plants are poisonous? And how do trees grow?",
        "à¸‰à¸±à¸™à¸Šà¸­à¸šà¸£à¸–à¹„à¸Ÿà¹à¸¥à¸°à¹€à¸ªà¹‰à¸™à¸—à¸²à¸‡à¸£à¸–à¹„à¸Ÿà¸¡à¸²à¸ à¹† à¸­à¸¢à¸²à¸à¸£à¸¹à¹‰à¸§à¹ˆà¸²à¹€à¸‚à¸²à¸§à¸²à¸‡à¹à¸œà¸™à¹€à¸„à¸£à¸·à¸­à¸‚à¹ˆà¸²à¸¢à¸£à¸²à¸‡à¸¢à¸±à¸‡à¹„à¸‡ à¹à¸¥à¹‰à¸§à¸—à¸³à¹„à¸¡à¹à¸•à¹ˆà¸¥à¸°à¸›à¸£à¸°à¹€à¸—à¸¨à¸£à¸°à¸šà¸šà¹„à¸Ÿà¸Ÿà¹‰à¸²à¹„à¸¡à¹ˆà¹€à¸«à¸¡à¸·à¸­à¸™à¸à¸±à¸™?",
        "I want to understand how the internet works: servers, DNS, networks, and how hackers hack (just to understand).",
        "TÃ´i thÃ­ch thiÃªn vÄƒn há»c nhÆ°ng cÅ©ng thÃ­ch sci-fi. MÃ¬nh muá»‘n biáº¿t nhá»¯ng thá»© sci-fi nÃ o lÃ  thá»±c táº¿.",
        "I want to do something with chemistry, maybe pharma or lab work. Iâ€™m interested in how medicines are developed.",
        "Ù…Ù† Ø¹Ù„Ø§Ù‚Ù‡â€ŒÙ…Ù†Ø¯ Ø¨Ù‡ Ø¬Ø§Ù…Ø¹Ù‡â€ŒØ´Ù†Ø§Ø³ÛŒâ€ŒØ§Ù…: Ú†Ø±Ø§ Ø¬Ø§Ù…Ø¹Ù‡ Ø§ÛŒÙ†Ø·ÙˆØ± Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ØŒ Ø±Ø³Ø§Ù†Ù‡â€ŒÙ‡Ø§ØŒ ØªØ±Ù†Ø¯Ù‡Ø§ØŒ ÙØ´Ø§Ø± Ú¯Ø±ÙˆÙ‡ÛŒ.",
        "Iâ€™m interested in animals, especially sea animals: dolphins, whales, octopuses. How are they so intelligent??",
        "Me interesan las computadoras pero la informÃ¡tica en la escuela es aburrida. Quiero saber cÃ³mo se crean apps de verdad.",
        "I like geography, countries, flags (yeah) and also natural disasters: earthquakes, tsunamis, volcanoes.",
        "Iâ€™m really into economics + philosophy together: what is a good life? capitalism? which systems are fair?",
        "à¦†à¦®à¦¿ à¦ à¦¿à¦• à¦¬à§à¦à¦¿ à¦¨à¦¾ à¦•à§€à¦­à¦¾à¦¬à§‡ à¦²à¦¿à¦–à¦¬, à¦•à¦¿à¦¨à§à¦¤à§ à¦†à¦®à¦¿ à¦…à¦¨à§‡à¦• à¦•à¦¿à¦›à§à¦° à¦ªà§à¦°à¦¤à¦¿ à¦†à¦—à§à¦°à¦¹à§€:\n- à¦®à¦¨à§‹à¦¬à¦¿à¦œà§à¦žà¦¾à¦¨ (à¦®à¦¾à¦¨à§à¦· à¦•à§‡à¦¨ à¦à¦®à¦¨ à¦¹à§Ÿ)\n- à¦…à¦ªà¦°à¦¾à¦§ à¦•à§‡à¦¸ à¦†à¦° à¦ªà§à¦°à¦®à¦¾à¦£ à¦•à§€à¦­à¦¾à¦¬à§‡ à¦¬à§‡à¦° à¦•à¦°à§‡\n- à¦†à¦° à¦œà§€à¦¬à¦¬à¦¿à¦œà§à¦žà¦¾à¦¨, à¦¬à¦¿à¦¶à§‡à¦· à¦•à¦°à§‡ à¦®à¦¸à§à¦¤à¦¿à¦·à§à¦•\nà¦†à¦®à¦¿ à¦­à¦¬à¦¿à¦·à§à¦¯à¦¤à§‡ à¦à¦®à¦¨ à¦•à¦¿à¦›à§ à¦•à¦°à¦¤à§‡ à¦šà¦¾à¦‡ à¦¯à§‡à¦–à¦¾à¦¨à§‡ à¦®à¦¾à¦¨à§à¦·à¦•à§‡ à¦¸à¦¾à¦¹à¦¾à¦¯à§à¦¯ à¦•à¦°à¦¾ à¦¯à¦¾à§Ÿ, à¦•à¦¿à¦¨à§à¦¤à§ à¦…à¦¨à§‡à¦• à¦šà¦¿à¦¨à§à¦¤à¦¾à¦“ à¦•à¦°à¦¤à§‡ à¦¹à§Ÿà¥¤ à¦ªà§à¦²à¦¿à¦œ à¦à¦•à¦¦à¦® à¦¬à§‹à¦°à¦¿à¦‚ à¦…à¦«à¦¿à¦¸ à¦œà¦¬ à¦¨à¦¾à¥¤",
        "Ø£Ù†Ø§ Ù…Ù‡ØªÙ… Ø¬Ø¯Ø§ Ø¨Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ØŒ Ø®ØµÙˆØµØ§: Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§ØªØŒ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ø§Ù„Ø´Ø¨ÙƒØ§Øª ÙˆØ£Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª. Ø£Ø¨Ø±Ù…Ø¬ Ù…Ø´Ø§Ø±ÙŠØ¹ ØµØºÙŠØ±Ø© ÙÙŠ ÙˆÙ‚Øª Ø§Ù„ÙØ±Ø§Øº (Ù…Ø«Ù„ Ø¨ÙˆØªØ§Øª Ø¯ÙŠØ³ÙƒÙˆØ±Ø¯ ÙˆØªØ·Ø¨ÙŠÙ‚Ø§Øª ÙˆÙŠØ¨) ÙˆØ£Ø±ÙŠØ¯ Ø£Ù† Ø£ÙÙ‡Ù… Ø£ÙƒØ«Ø± ÙƒÙŠÙ ØªØ¹Ù…Ù„ Ø£Ù†Ø¸Ù…Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„ØªØ´ÙÙŠØ±. ÙˆÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª ÙŠÙ‡Ù…Ù†ÙŠ Ø§Ù„Ø¬Ø§Ù†Ø¨ Ø§Ù„Ø£Ø®Ù„Ø§Ù‚ÙŠ Ù„Ù„ØªÙ‚Ù†ÙŠØ©: Ø§Ù„Ø®ØµÙˆØµÙŠØ©ØŒ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©ØŒ Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.",
        "Je veux ABSOLUMENT en savoir plus sur la mÃ©decine !!! Pas juste les Â« premiers secours Â», mais vraiment. Comment les organes fonctionnent ? Comment on fait les diagnostics ? Quâ€™est-ce qui se passe Ã  lâ€™hÃ´pital ? Et comment devient-on chirurgien ? Je regarde souvent des documentaires lÃ -dessus et Ã§a mâ€™intÃ©resse mÃ©gaaa ðŸ˜­",
        "I like fish and dinos and robots and space.",
        "Iâ€™m not sure what I want to be later. On one hand Iâ€™m interested in politics (because I get mad about a lot lol) and I want to understand how decisions are made and how to build good arguments. On the other hand I like natural sciences (biology and chemistry), and I find it fascinating how complex life comes from simple rules. I also like reading about history, especially revolutions and social change."
    ]

    if QUERY_SAMPLE_SEED:
        random.seed(QUERY_SAMPLE_SEED)
    sample_size = min(max(1, QUERY_SAMPLE_SIZE), len(queries))
    selected_queries = random.sample(queries, sample_size)

    LOG_DIR.mkdir(parents=True, exist_ok=True)
    with LOG_PATH.open("w", encoding="utf-8") as log:
        log.write(f"Model: {MODEL_NAME}\n")
        log.write(f"Topics: {len(topics)}; Tags: {len(tags)}\n")
        log.write(f"Assignments: {len(assignments)}\n\n")
        log.write(
            f"Query sample: {sample_size} of {len(queries)} "
            f"(seed={QUERY_SAMPLE_SEED or 'none'})\n\n"
        )

        for qi, query in enumerate(selected_queries, start=1):
            query_emb = model.encode([query], normalize_embeddings=True)[0]
            variant_scores = (query_emb @ tag_variant_emb.T).ravel()
            tag_scores = np.array(
                [
                    float(np.median(variant_scores[indices]))
                    for indices in tag_variant_indices
                ],
                dtype=float,
            )
            tag_weights = query_tag_weights(tag_scores, tags)

            log.write(f"=== Query {qi} ===\n{query}\n")
            log.write("Top query tags:\n")
            for tag_id, (name, score, weight) in sorted(
                tag_weights.items(), key=lambda t: t[1][2], reverse=True
            ):
                log.write(f"- {tag_id} {name}: sim={score:0.4f}, weight={weight:0.4f}\n")

            prefilter_scores: List[Tuple[str, float]] = []
            for topic_id, topic_tag_weights in assignments.items():
                score = 0.0
                for tag_id, (name, _, q_weight) in tag_weights.items():
                    t_weight = topic_tag_weights.get(tag_id)
                    if t_weight is not None:
                        score += q_weight * t_weight
                prefilter_scores.append((topic_id, score))

            prefilter_scores.sort(key=lambda item: item[1], reverse=True)
            third_score = prefilter_scores[2][1] if len(prefilter_scores) >= 3 else 0.0
            threshold = max(third_score * RELATIVE_MIN_FACTOR, ABS_MIN_PREFILTER)
            candidates = [item for item in prefilter_scores[:TOP_N_CANDIDATES] if item[1] >= threshold]

            log.write(
                f"\nPrefilter: {len(candidates)} candidates "
                f"(top {TOP_N_CANDIDATES}, threshold {threshold:0.4f})\n"
            )

            if not candidates:
                log.write("No candidates after prefilter.\n\n")
                continue

            candidate_indices = [topic_index[topic_id] for topic_id, _ in candidates]
            candidate_emb = topic_emb[candidate_indices]
            direct_scores = candidate_emb @ query_emb
            scored = list(zip(candidates, direct_scores))
            scored.sort(key=lambda item: item[1], reverse=True)

            log.write("Top final matches:\n")
            for (topic_id, pre_score), direct_score in scored[:TOP_FINAL]:
                topic = topic_by_id[topic_id]
                log.write(
                    f"- {topic_id} {topic.name}: pre={pre_score:0.4f}, final={float(direct_score):0.4f}\n"
                )
            log.write("\n")

    print(f"Log written to {LOG_PATH}")


if __name__ == "__main__":
    main()
